#!/usr/bin/env python3

# Import necessary modules
import json
import os

from openai import AzureOpenAI

# Load OpenAI configuration from JSON file
configuration_file_name = '../MagnusLiber.dev.json' if os.path.exists('../MagnusLiber.dev.json') else '../MagnusLiber.json'
with open(configuration_file_name, 'r') as file:
    configuration = json.load(file)

if configuration['openAiUri'].endswith('/'):
    configuration['openAiUri'] = configuration['openAiUri'][:-1]

# Load messages from JSON file
messages_file_name = '../Messages.json'
with open(messages_file_name, 'r') as file:
    messages = json.load(file, strict=False)

# Create OpenAI client
client = AzureOpenAI(
    # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#rest-api-versioning
    api_version = '2023-05-15',
    api_key = configuration['openAiKey'], 
    azure_endpoint = configuration['openAiUri'],
    # azure_deployment = configuration['deployment'],

    # Optional parameters included for demonstration purpose only
    max_retries=2,
    timeout=30,
)

# Load the system message
with open('../SystemMessage.txt', 'r') as file:
    system_message_text = file.read().strip()
    system_message = {
        'role': 'system',
        'content': system_message_text,
    }

# Create empty chat history
chat_history = []

 # Greet the user
print(messages['greeting'])

# Flag to determine if the loop should continue running
running = True

# Main loop
while running:
    # Prompt the user for input
    print(messages['prompt'])
    prompt = input().strip()

    if prompt == '':
        # User did not type a prompt. Display an appropriate message
        print(messages['emptyInput'])

    elif prompt in ['quit', 'exit']:
        # User typed `quit`` or `exit``. Display an appropriate message and exit the loop
        running = False

    else: # Get a response from the assistant        
        # Create user prompt
        user_message = {
            'role': 'user',
            'content': prompt
        }

        # Truncate chat history to the configured length
        if len(chat_history) >= configuration['historyLength']:
            chat_history = chat_history[2:]

        conversation = [system_message] + chat_history + [user_message]

        # Placeholder for making the actual call to the service
        # Adjust according to your actual API call
        chat_completion = client.chat.completions.create(
            messages=conversation,
            model=configuration['deployment'],  # Deployment name you created -- not model name.
            # the following parameter, `n`, represents how many responses should be generated by OpenAI
            n = 1,
            # The following parameters are optional and included for demonstration purpose only
            temperature=1.0,
            max_tokens=1500,
            top_p=1.0,
            frequency_penalty=0.0,
            presence_penalty=0.0,
        )

        # Get the assistant response
        # The `n` parameter for `client.chat.completions.create` determines how many responses are generated
        assistant_response = chat_completion.choices[0]  # Extract the first response (0)

        response = assistant_response.message.content

        # Add the user prompt and the assistant response to the chat history
        chat_history += [ 
            { 'role': 'user', 'content': prompt },
            { 'role': 'assistant', 'content': response } 
        ]

        # Display the assistant response
        print(response)
        print()  # Blank line for spacing

# User has exited the loop. Display an appropriate message
print(messages['exit'])

