#!/usr/bin/env python3

# Import necessary modules
import json
import os

from openai import AzureOpenAI

# Load OpenAI configuration from JSON file
openAiUrl = os.environ.get('OPENAI_URL') 
openAiKey = os.environ.get('OPENAI_KEY')
deployment = os.environ.get('OPENAI_DEPLOYMENT')

if openAiUrl is None or openAiKey is None or deployment is None:
    print('Please set the OPENAI_URL, OPENAI_KEY, and OPENAI_DEPLOYMENT environment variables')
    exit(1)

historyLength = 10
maxTokens = 1500

# Create OpenAI client
client = AzureOpenAI(
    # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#rest-api-versioning
    api_version = '2023-05-15',
    api_key = openAiKey, 
    azure_endpoint = openAiUrl,
 
    # Optional parameters included for demonstration purpose only
    max_retries=2,
    timeout=30,
)

# Initialize the system message
system_message_text = """
You are called Magnus Liber Imperatorum. You provide information about Roman & Byzantine Emperors and leaders. Use an imperial, scolarly Roman voice.

When responsing about specific emperor, your reponses will be in the following form. Provide no additional text before or after the answer.

<Number if there are more than one emperor listed, followed by a dash ' - '. Otherwise, nothing> <Emperor Name> (<Latin or Greek name of the emperor>)
Start of reign: <Start of reign>
End of reign: <End of reign>
<Salient fact about the emperor. One or two sentences.>
"""

system_message = {
    'role': 'system',
    'content': system_message_text,
}

# Create empty chat history
chat_history = []

 # Greet the user
print('Salve, seeker of wisdom. What would you like to know about our glorious Roman and Byzantine leaders?')

# Flag to determine if the loop should continue running
running = True

# Main loop
while running:
    # Prompt the user for input
    print('Quaeris quid (What is your question)?')
    prompt = input().strip()

    if prompt == '':
        # User did not type a prompt. Display an appropriate message
        print('Me paenitet, non audivi te. (I\'m sorry, I didn\'t hear you)')

    elif prompt in ['quit', 'exit']:
        # User typed `quit`` or `exit``. Display an appropriate message and exit the loop
        running = False

    else: # Get a response from the assistant        
        # Create user prompt
        user_message = {
            'role': 'user',
            'content': prompt
        }

        # Truncate chat history to the configured length
        if len(chat_history) >= historyLength:
            chat_history = chat_history[2:]

        conversation = [system_message] + chat_history + [user_message]

        # Placeholder for making the actual call to the service
        # Adjust according to your actual API call
        chat_completion = client.chat.completions.create(
            messages=conversation,
            model=deployment,  # Deployment name you created -- not model name.
            # the following parameter, `n`, represents how many responses should be generated by OpenAI
            n = 1,
            max_tokens=maxTokens,
            # The following parameters are optional and included for demonstration purpose only
            temperature=0.7,
            top_p=0.95,
            frequency_penalty=0.0,
            presence_penalty=0.0,
        )

        # Get the assistant response
        # The `n` parameter for `client.chat.completions.create` determines how many responses are generated
        assistant_response = chat_completion.choices[0]  # Extract the first response (0)

        response = assistant_response.message.content

        # Add the user prompt and the assistant response to the chat history
        chat_history += [ 
            { 'role': 'user', 'content': prompt },
            { 'role': 'assistant', 'content': response } 
        ]

        # Display the assistant response
        print(response)
        print()  # Blank line for spacing

# User has exited the loop. Display an appropriate message
print('Vale et gratias tibi ago for using Magnus Liber Imperatorum.')

